{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import spikeextractors as si\n",
    "import spikewidgets as sw\n",
    "import spiketoolkit as st\n",
    "import spikeforest as sf\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "from kbucket import client as kb\n",
    "from pairio import client as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the study\n",
    "study_dir='kbucket://b5ecdf1474c5/spikeforest/gen_synth_datasets/datasets_noise10_K20'\n",
    "study_name='synth_jfm_noise10_K20'\n",
    "num_datasets=None\n",
    "\n",
    "# Specify whether we want to do this offline\n",
    "offline=False\n",
    "\n",
    "# The following can be set for saving results\n",
    "PAIRIO_USER='spikeforest'\n",
    "PAIRIO_TOKEN=os.getenv('SPIKEFOREST_PAIRIO_TOKEN')\n",
    "KBUCKET_SHARE_ID='magland.spikeforest'\n",
    "KBUCKET_UPLOAD_TOKEN=os.getenv('SPIKEFOREST_KBUCKET_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the spike sorters\n",
    "sorters=[]\n",
    "ms4_params=dict(\n",
    "    detect_sign=-1,\n",
    "    adjacency_radius=-1,\n",
    "    detect_threshold=3\n",
    ")\n",
    "sorters.append(dict(\n",
    "    name='MountainSort4',\n",
    "    processor=sf.MountainSort4,\n",
    "    params=ms4_params\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pairio and kbucket\n",
    "\n",
    "if not offline:\n",
    "    # writing to pairio\n",
    "    if PAIRIO_USER:\n",
    "        pa.setConfig(user=PAIRIO_USER,token=PAIRIO_TOKEN)\n",
    "                     \n",
    "    # writing to kbucket              \n",
    "    if KBUCKET_UPLOAD_TOKEN:\n",
    "        print('Setting upload server to {}'.format(KBUCKET_SHARE_ID))\n",
    "        kb.setConfig(upload_share_id=KBUCKET_SHARE_ID,upload_token=KBUCKET_UPLOAD_TOKEN)\n",
    "        kb.testUpload()\n",
    "        \n",
    "    # reading from pairio and kbucket\n",
    "    pa.setConfig(collections=[PAIRIO_USER],local=False)\n",
    "    kb.setConfig(share_ids=[KBUCKET_SHARE_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datasets by reading the study directory\n",
    "datasets=[]\n",
    "dd=kb.readDir(study_dir)\n",
    "for dsname in dd['dirs']:\n",
    "    dsdir='{}/{}'.format(study_dir,dsname)\n",
    "    datasets.append(dict(\n",
    "        name=dsname,\n",
    "        dataset_dir=dsdir\n",
    "    ))\n",
    "if num_datasets is not None:\n",
    "    datasets=datasets[0:num_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for dataset in datasets:\n",
    "    for sorter in sorters:\n",
    "        print('SORTER: {}     DATASET: {}'.format(sorter['name'],dataset['name']))\n",
    "        result=sf.sortDataset(\n",
    "            sorter=sorter,\n",
    "            dataset=dataset,\n",
    "            _force_run=False\n",
    "        )\n",
    "        result['comparison_with_truth']=sf.compareWithTruth(result)\n",
    "        result['summary']=sf.summarizeSorting(result)\n",
    "        results.append(result)\n",
    "    #break\n",
    "print('Saving results object...')\n",
    "kb.saveObject(results,key=dict(name='spikeforest_results',study_name=study_name))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=kb.loadObject(key=dict(name='spikeforest_results',study_name=study_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.findFile(key=dict(name='spikeforest_results',study_name=study_name),remote_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(kb.realizeFile(results[0]['summary']['plots']['unit_waveforms']),format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def _read_text_file(path):\n",
    "  with open(path) as f:\n",
    "    return json.load(f)\n",
    "html=_read_text_file(kb.realizeFile(results[0]['comparison_with_truth']['html']))\n",
    "from IPython.display import HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
